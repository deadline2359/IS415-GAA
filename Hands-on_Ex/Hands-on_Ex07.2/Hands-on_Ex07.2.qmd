---
title: "In-class Exercise 7.2: Local Measures of Spatial Autocorrelation"
format: 
  html:
    code-line-numbers: true
    number-sections: true
    highlight-style: github
execute:
  warning: false
  echo: true  
  eval: true
editor: visual
date: "18 February 2023"
date-modified: "`r Sys.Date()`"
---

# Overview

::: callout-important
This exercise is an extension of [Hands-on Exercise 07.1](../Hands-on_Ex07.1/Hands-on_Ex07.1.html).

It has the same goals and datasets as this exercise.
:::

-   import geospatial data using appropriate function(s) of **sf** package,
-   import csv file using appropriate function of **readr** package, - perform relational join using appropriate join function of **dplyr** package,
-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of **spdep** package,
    -   plot [Moran scatterplot]{.underline},
    -   compute and plot spatial correlogram using appropriate function of **spdep** package.
-   compute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions **spdep** package;
-   compute [Getis-Ord's Gi-statistics]{.underline} for detecting hot spot or/and cold spot area by using appropriate functions of **spdep** package; and
-   to visualise the analysis output by using **tmap** package.

# Starting

## The Analytical Question

In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province.

**Task:** To apply appropriate spatial statistical methods to discover [**if development are even distributed geographically**]{.underline}.

-   If **YES**, our next question will be **"where are these clusters?"**.

-   If **NO**, our next question will be **"is there sign of spatial clustering?"**.

In this case study, we will be examining the spatial pattern of the GDP per capita of [Hunan Provice](https://en.wikipedia.org/wiki/Hunan), People Republic of China.

### The Study Area and Data

-   **Hunan province administrative boundary layer at county level** - Geospatial data set in ESRI shapefile format.
-   **Hunan_2012.csv** - This csv file contains selected Hunan's local development indicators in 2012.

## Setting Analytical Tools

-   **sf** is use for importing and handling geospatial data,
-   **tidyverse** is mainly use for wrangling attribute data,
-   **spdep** will mainly used to compute spatial weights, global and local spatial autocorrelation statistics, and
-   **tmap** will be used to prepare cartographic quality chropleth map.

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, ggplot2)
```

# Getting the Data Into R Environment

## Importing

### Importing Shapefile

The code chunk below uses [`st_read()`](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be of **simple features** Object.

::: panel-tabset
#### Importing

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

#### Dataset

```{r}
head(hunan, 5)
```
:::

### Import csv file into r environment

Next, we will import *Hunan_2012.csv* into R by using `read_csv()` of **readr** package. The output is **R dataframe class**.

::: panel-tabset
#### Import

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

#### Dataset

```{r}
head(hunan2012, 5)
```
:::

## Performing Relational Join

The code chunk below will be used to update the attribute table of *hunan*'s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using `left_join()` of **dplyr** package.

::: panel-tabset
### Joining

```{r}
hunan <- left_join(hunan,hunan2012) %>%
  select(1:4, 7, 15)
```

### Dataset

```{r}
head(hunan, 5)
```
:::

## Visualising Regional Development Indicator

Now, a basemap and a choropleth map will be prepared to show the **distribution of GDPPC 2012** by using `qtm()` of **tmap** package.

```{r}
# data classification: equal
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

# data classification: quantile 
quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

# Global Spatial Autocorrelation

In this section, we will compute **global spatial autocorrelation** statistics and perform **spatial complete randomness test** for global spatial autocorrelation.

## Computing Contiguity Spatial Weights

Before computing the global spatial autocorrelation statistics, **spatial weights** of the study area need to be constructed. The spatial weights is used to **define the neighbourhood relationships between the geographical units** (i.e., county) in the study area.

In the code chunk below, [`poly2nb()`](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package is used to compute **contiguity weight matrices** for the study area. This function [builds a neighbours list based on regions with contiguous boundaries]{.underline}.

-   The "**queen**" argument takes a boolean (default: TRUE). If specified to be TRUE, the function will **return a [list]{.underline} of first order neighbours** using the Queen criteria.

More specifically, the code chunk below is used to compute **Queen contiguity weight matrix**.

```{r}
wm_q <- poly2nb(hunan, 
                queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.

## Row-standardised Weights Matrix

Next, weights will be assigned to each neighboring polygon.

In our case, each neighbouring polygon will be assigned equal weight (style="W"). This is accomplished by

1.  assigning $\frac{1}{Number Of Neighbours}$ to each neighboring county then,
2.  summing the **weighted income values**.

While this is the most intuitive way to summarise the neighbors' values, it has one *drawback* in that the polygons along the edges of the study area will base their lagged values on fewer polygons, thus **potentially over- or under-estimating the true nature of the spatial autocorrelation** in the data.

For this example, we'll stick with the style="W" option for simplicity's sake but note that other more robust options are available, notably style="B".

```{r}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```

The input of `nb2listw()` must be an object of class **nb**. The syntax of the function has two major arguments, namely style and zero.poly.

-   *style* can take values "W", "B", "C", "U", "S" and "minmax".
    -   B is the basic binary coding,
    -   W is row standardised (sums over all links to n),
    -   C is globally standardised (sums over all links to n),
    -   U is equal to C divided by the number of neighbours (sums over all links to unity), while
    -   S is the variance-stabilizing coding scheme proposed (sums over all links to n).
    -   minmax divides the weights by the minimum of the maximum row sums and maximum column sums of the input weights. It is similar to the C and U styles.
-   If *zero policy* is set to **TRUE**, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %\*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.
    -   If **FALSE**, stop with error for any empty neighbour sets

## Global Spatial Autocorrelation: Moran's I

### Maron's I test

The code chunk below performs Moran's I statistical testing using [`moran.test()`](https://r-spatial.github.io/spdep/reference/moran.test.html) of **spdep**.

```{r}
moran.test(hunan$GDPPC, 
           listw=rswm_q, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

[**Result**]{.underline}

-   **statistic** - the value of the standard deviate of Moran's I.
-   **p.value** - the p-value of the test.
-   **estimate** - the value of the observed Moran's I, its expectation and variance under the method assumption.
-   **alternative** - a character string describing the alternative hypothesis.
-   **method** - a character string giving the assumption used for calculating the standard deviate.
-   **data.name** - a character string giving the name(s) of the data.

::: callout-note
#### Guess

The p-value is really small. Hence, the null hypothesis is rejected, which means development is not distributed equally across the region.
:::

### Computing Monte Carlo Moran's I

The code chunk below performs permutation test for Moran's I statistic by using [`moran.mc()`](https://r-spatial.github.io/spdep/reference/moran.mc.html) of **spdep**. A total of 1000 simulation will be performed.

```{r}
set.seed(1234)
bperm = moran.mc(hunan$GDPPC, 
                listw=rswm_q, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

[**Parameters**]{.underline}

-   **listw** - **listw** objected created by `nb2listw()`.
-   **nsim** - number of permutations.
-   **zero.policy** - if TRUE, assign zero to the lagged value of zones without neighbours; if FALSE, assign NA
-   **alternative** - a character string describing the alternative hypothesis, must be either "greater" (default), "two.sided", or "less".
-   **na.action** - default `na.fail`, can also be `na.omit` or `na.exclude`. In these cases, the weights list will be subsetted to remove NAs in the data.
    -   It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations.

::: callout-note
#### Guess

The p-value is very small. Hence, the null hypothesis is rejected, which means development is not distributed equally across the region.
:::

### Visualising Monte Carlo Moran's I

It is always a good practice to examine the simulated Moran's I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.

In the code chunk below [`hist()`](https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/hist) and [`abline()`](https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/abline) of R Graphics are used.

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```

::: callout-note
#### Guess

The distribution is quite normalised but skews towards to the right.
:::

### 

## Global Spatial Autocorrelation: Geary's

In this section, Geary's C statistics testing is performed by using appropriate functions of **spdep** package.

### Geary's C test

The code chunk below performs Geary's C test for spatial autocorrelation by using [`geary.test()`](https://r-spatial.github.io/spdep/reference/geary.test.html) of **spdep**.

```{r}
geary.test(hunan$GDPPC, listw=rswm_q)
```

::: callout-note
#### Guess

The p-value is really small. Hence, the null hypothesis is rejected, which means development is not distributed equally across the region.
:::

### Computing Monte Carlo Geary's C

The code chunk below performs permutation test for Geary's C statistic by using [`geary.mc()`](https://r-spatial.github.io/spdep/reference/geary.mc.html) of **spdep**.

```{r}
set.seed(1234)
bperm=geary.mc(hunan$GDPPC, 
               listw=rswm_q, 
               nsim=999)
bperm
```

::: callout-note
#### Guess

The p-value is really small. Hence, the null hypothesis is rejected, which means development is not distributed equally across the region.
:::

### Visualising the Monte Carlo Geary's C

Next, a histogram will be plotted to reveal the distribution of the simulated values by using the code chunk below.

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Geary c")
abline(v=1, col="red") 
```

# Spatial Correlogram

Spatial correlograms are **great to examine patterns of spatial autocorrelation** in your data or model residuals.

They show [how correlated are pairs of spatial observations]{.underline} when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran's I or Geary's c) against distance. Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.

## Compute Moran's I correlogram

In the code chunk below, [`sp.correlogram()`](https://r-spatial.github.io/spdep/reference/sp.correlogram.html) of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran's I. The **`plot()`** of base Graph is then used to plot the output.

```{r}
MI_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="I", 
                          style="W")
plot(MI_corr)
```

Plotting the output might not provide a complete interpretation. This is because **not all autocorrelation values are statistically significant**. Hence, it is important to examine the full analysis report by printing out the analysis results as in the code chunk below.

```{r}
print(MI_corr)
```

### 

## Compute Geary's C correlogram and plot

In the code chunk below, `sp.correlogram()` of **spdep** package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary's C. The **`plot()`** of base Graph is then used to plot the output.

```{r}
GC_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="C", 
                          style="W")
plot(GC_corr)
```

Similar to the previous step, we will print out the analysis report by using the code chunk below.

```{r}
print(GC_corr)
```

# Cluster and Outlier Analysis

**Local Indicators of Spatial Association (LISA)** are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable.

For instance if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that **there** **are areas that have higher or lower rates than is to be expected** by chance alone; that is, the values occurring are above or below those of a random distribution in space.

In this section, the appropriate LISA, especially local Moran's I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.

## Computing Local Moran's I

To compute local Moran's I, the [`localmoran()`](https://r-spatial.github.io/spdep/reference/localmoran.html) function of **spdep** will be used. It computes *Ii* values, given a set of *zi* values and a **listw** object providing neighbour weighting information for the polygon associated with the *zi* values.

The code chunks below are used to compute local Moran's I of *GDPPC2012* at the county level.

```{r}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

`localmoran()` function returns a matrix of values whose columns are:

-   **Ii:** the local Moran's I statistics
-   **E.Ii:** the expectation of local moran statistic under the randomisation hypothesis
-   **Var.Ii:** the variance of local moran statistic under the randomisation hypothesis
-   **Z.Ii:** the standard deviate of local moran statistic
-   **Pr():** the p-value of local moran statistic

The code chunk below list the content of the local Moran matrix derived by using [`printCoefmat()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/printCoefmat).

```{r}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=hunan$County[fips]),
  check.names=FALSE)
```

### Mapping Local Moran's I

Before mapping the local Moran's I map, it is wise to append the local Moran's I dataframe (i.e., localMI) onto **hunan** SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called *hunan.localMI*.

```{r}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

### 

Mapping Local Moran's I values

Using choropleth mapping functions of **tmap** package, the local Moran's I values can be plotted by using the code chunk below.

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

### Mapping Local Moran's I p-values

The choropleth shows there is evidence for both positive and negative *Ii* values. However, it is useful to consider the p-values for each of these values, as consider above.

The code chunks below produce a choropleth map of Moran's I p-values by using functions of **tmap** package.

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

### Mapping Both Local Moran's I values and p-values

For effective interpretation, it is better to plot both the local Moran's I values map and its corresponding p-values map next to each other.

The code chunk below will be used to create such visualisation.

```{r}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

# Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

## Plotting Moran Scatterplot

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

The code chunk below plots the Moran scatterplot of GDPPC 2012 by using [`moran.plot()`](https://r-spatial.github.io/spdep/reference/moran.plot.html) of **spdep**.

```{r}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```

::: callout-note
Notice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. These are the high-high locations in the lesson slide.
:::

## Plotting Moran Scatterplot with Standardised Variable

First, scale() will be used to center and scale the variable. Here, centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% 
  as.vector 
```

The [`as.vector()`](https://www.rdocumentation.org/packages/pbdDMAT/versions/0.5-1/topics/as.vector) added to the end is to make sure that the resulting data type is a vector, which will map neatly into a dataframe.

Now, the Moran scatterplot can be plotted again by using the code chunk below.

```{r}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

## Preparing LISA Map Classes

The code chunks below show the steps to prepare a LISA cluster map.

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Next, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.

```{r}
hunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     
```

This is follow by centering the local Moran's around the mean.

```{r}
LM_I <- localMI[,1] - mean(localMI[,1])
```

Next, a statistical significance level will be set for the local Moran.

```{r}
signif <- 0.05
```

These four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.

```{r}
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4
```

Lastly, places non-significant Moran in the category 0.

```{r}
quadrant[localMI[,5]>signif] <- 0
```

In fact, all the steps can be combined into one single code chunk as shown below:

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
hunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     
LM_I <- localMI[,1]   
signif <- 0.05       
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4    
quadrant[localMI[,5]>signif] <- 0
```

## Plotting LISA map

Now, the LISA map can be built by using the code chunks below.

```{r}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

For effective interpretation, it is better to plot both the local Moran's I values map and its corresponding p-values map next to each other.

The code chunk below will be used to create such visualisation.

```{r}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(gdppc, LISAmap, 
             asp=1, ncol=2)
```

We can also include the local Moran's I map and p-value map as shown below for easy comparison.

Variable(s) "Ii" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.

```{r echo=FALSE}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

# Hot Spot and Cold Spot Area Analysis

Beside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.

The term 'hot spot' has been used generically across disciplines to describe a region or value that is higher relative to its surroundings.

## Getis and Ord's G-Statistics

An alternative spatial statistics to detect spatial anomalies is the Getis and Ord's G-statistics. It **looks at neighbours within a defined proximity** to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.

The analysis consists of three steps:

1.  Deriving spatial weight matrix
2.  Computing Gi statistics
3.  Mapping Gi statistics

## Deriving Distance-based Weight Matrix

First, a new set of neighbours needs to be defined. Whist the spatial autocorrelation considered units which shared borders, we are defining neighbours based on distance for Getis-Ord.

There are two type of distance-based proximity matrix, they are:

-   fixed distance weight matrix; and
-   adaptive distance weight matrix.

### Deriving the Centroid

Points are needed to associate with each polygon before making a connectivity graph. It will be a little more complicated than just running `st_centroid()` on the sf object: **us.bound**. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be `st_centroid()`. We will be using map_dbl variation of map from the purrr package.

To get our longitude values we map the `st_centroid()` function over the geometry column of us.bound and access the longitude value through double bracket notation \[\[\]\] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

We do the same for latitude with one key difference. We access the second value per each centroid with \[\[2\]\].

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Now that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.

```{r}
coords <- cbind(longitude, latitude)
```

### Determine the Cut-off Distance

Firstly, the upper limit for distance band needs to be determined using the steps below:

1.  Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using [`knearneigh()`](https://r-spatial.github.io/spdep/reference/knearneigh.html) of **spdep**.
2.  Convert the knn object returned by `knearneigh()` into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using [`knn2nb()`](https://r-spatial.github.io/spdep/reference/knn2nb.html).
3.  Return the length of neighbour relationship edges by using [`nbdists()`](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.
4.  Remove the list structure of the returned object by using [**`unlist()`**](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

### Computing Fixed Distance Weight Matrix

Now, the distance weight matrix will be calculated by using [`dnearneigh()`](https://r-spatial.github.io/spdep/reference/dnearneigh.html) as shown in the code chunk below.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Next, `nb2listw()` is used to convert the nb object into spatial weights object.

```{r}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

## Computing Adaptive Distance Weight Matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

Next, `nb2listw()` is used to convert the nb object into spatial weights object.

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

# Computing *Gi* statistics

## *Gi* Statistics using Fixed Distance

```{r}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

The output of `localG()` is a vector of G or Gstar values, with attributes \"gstari\" set to TRUE or FALSE, \"call\" set to the function call, and class \"localG\".

The *Gi* statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.

Next, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.

```{r}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
hunan.gi
```

In fact, the code chunk above performs three tasks.

1.  It convert the output vector (i.e. *gi.fixed*) into r matrix object by using `as.matrix()`.

2.  `cbind()` is used to join hunan\@data and *gi.fixed* matrix to produce a new SpatialPolygonDataFrame called *hunan.gi*.

3.  The field name of the *gi* values is renamed to *gstat_fixed* by using `rename()`.

## Mapping *Gi* values with Fixed Distance Weights

The code chunk below shows the functions used to map the *Gi* values derived using fixed distance weight matrix.

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

## *Gi* Statistics using Adaptive Distance

The code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e *knb_lw*).

```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

## Mapping *Gi* Values with Adaptive Distance Weights

It is time to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of **tmap** package will be used to map the *Gi* values.

The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{r}
gdppc<- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, 
             Gimap, 
             asp=1, 
             ncol=2)
```
